/*
 * ofxLlamaCpp
 *
 * Copyright (c) 2025 Yannick Hofmann
 * <contact@yannickhofmann.de>
 *
 * BSD Simplified License.
 * For information on usage and redistribution, and for a DISCLAIMER OF ALL
 * WARRANTIES, see the file, "LICENSE.txt," in this distribution.
 */
 
#include "ofUtils.h"
#include "ofApp.h"

//--------------------------------------------------------------
// setup() is called once when the application starts.
void ofApp::setup() {
    // Set the background color to black.
    ofBackground(0);
    // Set the drawing color to white.
    ofSetColor(255);
    // Set the frame rate to 60 frames per second.
    ofSetFrameRate(60);

    // Initialize the modelLoaded flag to false.
    modelLoaded = false;

    // --- Basic Llama Setup ---
    // 1. Load the model.
    //    You can download other models and place them in the bin/data folder.
    //    Ensure the path to the model is correct.
    if (llama.loadModel(ofToDataPath("Teuken-7B-instruct-commercial-v0.4.Q4_K_M.gguf"), 2048)) {
        ofLogNotice() << "Model loaded successfully.";
        modelLoaded = true;
        
        // 2. Set generation parameters (optional).
        //    Temperature controls the randomness of the output. Higher values make it more random.
        llama.setTemperature(0.8f);
        //    Top-K sampling limits the next token selection to the K most likely tokens.
        llama.setTopK(40);

        // Add stop words to prevent the model from generating past a certain point.
        // This is useful for stopping the generation after the assistant's response.
        llama.addStopWord("User:");
        llama.addStopWord("Assistant:");

        // 3. Create a prompt and start the generation process.
        prompt = "What is openFrameworks?\n\nAssistant:";
        // Start generating text with a maximum length of 1024 tokens.
        llama.startGeneration(prompt, 1024);

        ofLogNotice() << "Started generation for prompt: " << prompt;

    } else {
        ofLogError() << "Model load failed!";
        output = "Failed to load model.";
    }
}

//--------------------------------------------------------------
// update() is called repeatedly in a loop, updating the application's state.
void ofApp::update() {
    // Append any new text generated by the Llama model to the output string.
    // getNewOutput() returns only the text generated since the last call.
    output += llama.getNewOutput();
}

//--------------------------------------------------------------
// draw() is called repeatedly to render visuals to the screen.
void ofApp::draw() {
    // Draw the initial prompt on the screen.
    ofSetColor(255); // Set color to white for the prompt.
    ofDrawBitmapString("Prompt: " + prompt, 20, 50);

    // Set the text color based on the application's state.
    if (!modelLoaded) {
        ofSetColor(255, 0, 0); // Red color indicates an error.
    } else {
        ofSetColor(173, 255, 47); // Light green for the generated output.
    }

    // Prepare and draw the main output text from the model.
    std::string textToDraw = output;
    // Remove the "Assistant:" prefix if it exists, for cleaner display.
    if (startsWith(textToDraw, "Assistant:")) {
        textToDraw = textToDraw.substr(std::string("Assistant:").length());
    }
    // Wrap the text to fit within half of the screen width.
    std::string wrappedOutput = wrapString(textToDraw, ofGetWidth() / 2);
    // Draw the wrapped text.
    ofDrawBitmapString(wrappedOutput, 20, 100);

    // Reset the color to white for any other UI elements.
    ofSetColor(255);

    // Display the current generation status at the bottom of the screen.
    if (llama.isGenerating()) {
        ofDrawBitmapString("Generating...", 20, ofGetHeight() - 30);
    } else {
        if (modelLoaded) {
            ofDrawBitmapString("Generation finished.", 20, ofGetHeight() - 30);
        }
    }
}

//--------------------------------------------------------------
// A helper function to wrap a long string of text to a specified width.
std::string ofApp::wrapString(std::string text, int width) {
    std::string wrappedText;
    std::string currentLine;
    ofBitmapFont font; // Use the default bitmap font for calculating text width.

    // Replace all newline characters with spaces to handle pre-formatted text.
    std::replace(text.begin(), text.end(), '\n', ' ');

    // Split the text into individual words.
    std::vector<std::string> words = ofSplitString(text, " ", true, true);

    // Iterate through the words and build lines of wrapped text.
    for (size_t i = 0; i < words.size(); ++i) {
        std::string word = words[i];
        // If adding the next word exceeds the width, start a new line.
        if (font.getBoundingBox(currentLine + word, 0, 0).width > width) {
            wrappedText += currentLine + "\n";
            currentLine = "";
        }
        if (!currentLine.empty()) {
            currentLine += " ";
        }
        currentLine += word;
    }
    // Add the last line to the wrapped text.
    wrappedText += currentLine;

    return wrappedText;
}

//--------------------------------------------------------------
// A helper function to check if a string starts with a given prefix.
bool ofApp::startsWith(const std::string& text, const std::string& prefix) {
    return text.size() >= prefix.size() && text.rfind(prefix, 0) == 0;
}
